{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G2H2_e_Q89C6",
        "outputId": "fb727bd5-1293-4fe0-8c4b-a53cc5dc80a8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (9.4.0)\n"
          ]
        }
      ],
      "source": [
        "from tensorflow import keras\n",
        "import tensorflow as tf\n",
        "from keras import models\n",
        "import PIL\n",
        "from keras import layers\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.keras.models import Sequential\n",
        "!pip install Pillow"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HMYU3zsmLqMa"
      },
      "source": [
        "## Download and explore datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "cTvn9Dq-gU_5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6bd5ceca-7b38-4523-f9d4-f5fe5c8e026a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mkdir: cannot create directory ‘/root/.kaggle’: File exists\n"
          ]
        }
      ],
      "source": [
        "!mkdir ~/.kaggle\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dGfgVqrdh8zQ",
        "outputId": "1ef708fd-ea4e-44a4-b0a2-e14554bb0633"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mv: cannot stat 'kaggle.json': No such file or directory\n"
          ]
        }
      ],
      "source": [
        "!mv kaggle.json ~/.kaggle\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GTIfPKa0iCIK",
        "outputId": "f169423e-0526-4a9c-907d-4f9c7b451ca6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            ".  ..\n"
          ]
        }
      ],
      "source": [
        "!ls -a ~/.kaggle\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ynTUl16LiOGT",
        "outputId": "14e53d39-2d7a-44ad-b400-299d08196c53"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset URL: https://www.kaggle.com/datasets/aima138/17flowerclasses\n",
            "License(s): unknown\n",
            "17flowerclasses.zip: Skipping, found more recently modified local copy (use --force to force download)\n"
          ]
        }
      ],
      "source": [
        "!kaggle datasets download -d aima138/17flowerclasses\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iLjD-UcEiZ7y",
        "outputId": "11a4c53c-de0b-4b28-a2e6-57a9f8534c76"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  17flowerclasses.zip\n",
            "replace 17flowerclasses/test/Bluebell/image_0246.jpg? [y]es, [n]o, [A]ll, [N]one, [r]ename: "
          ]
        }
      ],
      "source": [
        "! unzip 17flowerclasses.zip"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sXHpPj6uKmFH"
      },
      "source": [
        "# Load data with keras"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install tqdm"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x35T1pc4-FNK",
        "outputId": "bbe8c527-0470-41e4-99bf-2caf123603c7"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (4.66.4)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install timm"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6JrZKSMTES_t",
        "outputId": "35515d50-024d-44d3-c89f-0cfe6b0c54a2"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: timm in /usr/local/lib/python3.10/dist-packages (1.0.7)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from timm) (2.3.1+cu121)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (from timm) (0.18.1+cu121)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from timm) (6.0.1)\n",
            "Requirement already satisfied: huggingface_hub in /usr/local/lib/python3.10/dist-packages (from timm) (0.23.5)\n",
            "Requirement already satisfied: safetensors in /usr/local/lib/python3.10/dist-packages (from timm) (0.4.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface_hub->timm) (3.15.4)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub->timm) (2023.6.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub->timm) (24.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface_hub->timm) (2.31.0)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub->timm) (4.66.4)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub->timm) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->timm) (1.13.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->timm) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->timm) (3.1.4)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->timm) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->timm) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->timm) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch->timm) (8.9.2.26)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch->timm) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch->timm) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch->timm) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch->timm) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch->timm) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /usr/local/lib/python3.10/dist-packages (from torch->timm) (2.20.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->timm) (12.1.105)\n",
            "Requirement already satisfied: triton==2.3.1 in /usr/local/lib/python3.10/dist-packages (from torch->timm) (2.3.1)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch->timm) (12.5.82)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision->timm) (1.25.2)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision->timm) (9.4.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->timm) (2.1.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub->timm) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub->timm) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub->timm) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub->timm) (2024.7.4)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->timm) (1.3.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, random_split\n",
        "from torchvision import datasets, transforms\n",
        "from tqdm import tqdm\n",
        "import timm\n",
        "import gc\n",
        "from torch.cuda.amp import GradScaler, autocast\n",
        "\n",
        "# Define the device to use GPU if available\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Define the transformations for the train and test sets\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((299, 299)),  # Resize images to 128x128 pixels to save memory\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "# Define the dataset directories\n",
        "train_dir = '/content/17flowerclasses/train'\n",
        "test_dir = '/content/17flowerclasses/test'\n",
        "\n",
        "# Create datasets\n",
        "full_train_dataset = datasets.ImageFolder(root=train_dir, transform=transform)\n",
        "test_dataset = datasets.ImageFolder(root=test_dir, transform=transform)\n",
        "\n",
        "# Split the training dataset into training and validation sets\n",
        "train_size = int(0.8 * len(full_train_dataset))\n",
        "val_size = len(full_train_dataset) - train_size\n",
        "train_dataset, val_dataset = random_split(full_train_dataset, [train_size, val_size])\n",
        "\n",
        "# Reduce batch size to save memory\n",
        "batch_size = 16\n",
        "num_workers = 2\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=num_workers, pin_memory=True)\n",
        "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, num_workers=num_workers, pin_memory=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=num_workers, pin_memory=True)\n",
        "\n",
        "# Print some information about the dataset\n",
        "print(f\"Number of training samples: {len(train_dataset)}\")\n",
        "print(f\"Number of validation samples: {len(val_dataset)}\")\n",
        "print(f\"Number of testing samples: {len(test_dataset)}\")\n",
        "print(f\"Number of classes: {len(full_train_dataset.classes)}\")\n",
        "print(f\"Class names: {full_train_dataset.classes}\")\n",
        "\n",
        "# Define the neural network (using a pre-trained EfficientNet-B0 model)\n",
        "model = timm.create_model('tf_efficientnet_b0_ns', pretrained=True)\n",
        "model.classifier = nn.Linear(model.classifier.in_features, len(full_train_dataset.classes))\n",
        "model = model.to(device)\n",
        "\n",
        "# Define the loss function and optimizer\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "# Mixed Precision Training\n",
        "scaler = GradScaler()\n",
        "\n",
        "# Training function with gradient accumulation and accuracy calculation\n",
        "def train_single_model(model, train_loader, validation_loader, criterion, optimizer, scaler, num_epochs=8, accumulation_steps=4):\n",
        "    best_val_accuracy = 0.0\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        model.train()\n",
        "        running_loss = 0.0\n",
        "        correct_train = 0\n",
        "        total_train = 0\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        for i, (inputs, labels) in enumerate(tqdm(train_loader, desc=f\"Epoch {epoch+1}/{num_epochs}\")):\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "            with autocast():  # Mixed precision training\n",
        "                outputs = model(inputs)\n",
        "                loss = criterion(outputs, labels)\n",
        "                loss = loss / accumulation_steps  # Normalize the loss to account for gradient accumulation\n",
        "            scaler.scale(loss).backward()\n",
        "\n",
        "            if (i + 1) % accumulation_steps == 0:  # Perform optimizer step after accumulating gradients\n",
        "                scaler.step(optimizer)\n",
        "                scaler.update()\n",
        "                optimizer.zero_grad()\n",
        "\n",
        "            running_loss += loss.item()\n",
        "\n",
        "            # Calculate training accuracy\n",
        "            _, predicted = torch.max(outputs, 1)\n",
        "            correct_train += (predicted == labels).sum().item()\n",
        "            total_train += labels.size(0)\n",
        "\n",
        "        epoch_loss = running_loss / len(train_loader)\n",
        "        epoch_acc_train = correct_train / total_train * 100.0\n",
        "        print(f'Epoch {epoch+1}/{num_epochs}, Training Loss: {epoch_loss:.4f}, Training Accuracy: {epoch_acc_train:.2f}%')\n",
        "\n",
        "        # Validation phase\n",
        "        model.eval()\n",
        "        validation_loss = 0.0\n",
        "        correct_val = 0\n",
        "        total_val = 0\n",
        "        with torch.no_grad():\n",
        "            for inputs, labels in val_loader:\n",
        "                inputs, labels = inputs.to(device), labels.to(device)\n",
        "                with autocast():  # Mixed precision training\n",
        "                    outputs = model(inputs)\n",
        "                    loss = criterion(outputs, labels)\n",
        "                validation_loss += loss.item()\n",
        "\n",
        "                # Calculate validation accuracy\n",
        "                _, predicted = torch.max(outputs, 1)\n",
        "                correct_val += (predicted == labels).sum().item()\n",
        "                total_val += labels.size(0)\n",
        "\n",
        "        epoch_val_loss = validation_loss / len(val_loader)\n",
        "        epoch_acc_val = correct_val / total_val * 100.0\n",
        "        print(f'Epoch {epoch+1}/{num_epochs}, Validation Loss: {epoch_val_loss:.4f}, Validation Accuracy: {epoch_acc_val:.2f}%')\n",
        "\n",
        "        # Save the best model based on validation accuracy\n",
        "        if epoch_acc_val > best_val_accuracy:\n",
        "            best_val_accuracy = epoch_acc_val\n",
        "            best_model_wts = model.state_dict()\n",
        "\n",
        "        # Clear cache\n",
        "        torch.cuda.empty_cache()\n",
        "        gc.collect()\n",
        "\n",
        "    # Load the best model weights\n",
        "    model.load_state_dict(best_model_wts)\n",
        "    return model\n",
        "\n",
        "# Train the model\n",
        "model = train_single_model(model, train_loader, val_loader, criterion, optimizer, scaler, num_epochs=8, accumulation_steps=4)\n",
        "\n",
        "# Evaluating the model on the test set\n",
        "model.eval()\n",
        "correct_test = 0\n",
        "total_test = 0\n",
        "with torch.no_grad():\n",
        "    for inputs, labels in test_loader:\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "        outputs = model(inputs)\n",
        "        _, predicted = torch.max(outputs, 1)\n",
        "        total_test += labels.size(0)\n",
        "        correct_test += (predicted == labels).sum().item()\n",
        "\n",
        "print(f\"Accuracy of the model on the test images: {100 * correct_test / total_test:.2f}%\")\n"
      ],
      "metadata": {
        "id": "WlsuaX-pWCOk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "313a711e-450c-4a4b-a4b9-e4c042925b5b"
      },
      "execution_count": 2,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of training samples: 952\n",
            "Number of validation samples: 238\n",
            "Number of testing samples: 170\n",
            "Number of classes: 17\n",
            "Class names: ['Bluebell', 'ButterCup', 'ColtsFoot', 'Cowslip', 'Crocus', 'Daffodil', 'Daisy', 'Dandelion', 'Fritillary', 'Iris', 'LilyValley', 'Pansy', 'Snowdrop', 'Sunflower', 'Tigerlily', 'WindFlower', 'tulip']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1/8: 100%|██████████| 60/60 [09:29<00:00,  9.50s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/8, Training Loss: 0.3994, Training Accuracy: 71.11%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/8, Validation Loss: 0.2103, Validation Accuracy: 97.06%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 2/8: 100%|██████████| 60/60 [09:29<00:00,  9.49s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2/8, Training Loss: 0.0488, Training Accuracy: 95.59%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2/8, Validation Loss: 0.0837, Validation Accuracy: 97.90%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 3/8: 100%|██████████| 60/60 [09:31<00:00,  9.52s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 3/8, Training Loss: 0.0181, Training Accuracy: 98.00%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 3/8, Validation Loss: 0.1003, Validation Accuracy: 97.06%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 4/8: 100%|██████████| 60/60 [09:29<00:00,  9.48s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 4/8, Training Loss: 0.0157, Training Accuracy: 98.32%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 4/8, Validation Loss: 0.0613, Validation Accuracy: 97.90%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 5/8: 100%|██████████| 60/60 [09:28<00:00,  9.48s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 5/8, Training Loss: 0.0090, Training Accuracy: 99.16%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 5/8, Validation Loss: 0.0486, Validation Accuracy: 99.16%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 6/8: 100%|██████████| 60/60 [09:25<00:00,  9.42s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 6/8, Training Loss: 0.0041, Training Accuracy: 99.47%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 6/8, Validation Loss: 0.0506, Validation Accuracy: 98.32%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 7/8: 100%|██████████| 60/60 [09:29<00:00,  9.50s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 7/8, Training Loss: 0.0061, Training Accuracy: 99.37%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 7/8, Validation Loss: 0.0610, Validation Accuracy: 98.74%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 8/8: 100%|██████████| 60/60 [09:35<00:00,  9.59s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 8/8, Training Loss: 0.0071, Training Accuracy: 99.37%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 8/8, Validation Loss: 0.0643, Validation Accuracy: 98.74%\n",
            "Accuracy of the model on the test images: 96.47%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "TUQsIufWWCRS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FUpEQdLvRg7o"
      },
      "source": [
        "# Keras Model"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "PsQl1UFuUc9S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sJxYrecuR_ZC"
      },
      "source": [
        "# Train the model"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "sI6geatgRLJU"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}